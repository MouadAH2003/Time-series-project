Alors Notre architecture proposée vise à capturer de façon optimale les dépendances temporelles aux différentes échelles dans les données, pour une prédiction précise des séries temporelles.

Les 2 premières couches LSTM avec (return_sequences=True) modèlisent les dépendances à très long terme sur toute la séquence d'entrée de taille time_step. 

Elles encodent une représentation riche des informations temporelles globales sur la fenetres complète.

La couche de Convolution 1D  :nous ajoutons une couche de convolution à une architecture de modèle (dans ce cas, un modèle séquentiel). La couche de convolution est définie avec 32 filtres (ou noyaux) et une taille de noyau de 5. La fonction d'activation utilisée est ReLU (Rectified Linear Unit).

Les filtres de la couche de convolution agissent comme des détecteurs de motifs locaux dans les données d'entrée. Chaque filtre est appliqué à une fenêtre glissante des données d'entrée pour extraire des caractéristiques spécifiques.

C'est la taille de la fenêtre utilisée pour l'opération de convolution. Une taille de noyau de 5 signifie que la convolution est appliquée à des sous-séquences de longueur 5 dans les données d'entrée.

=> LA couche de convolution est essentielle pour extraire des motifs locaux significatifs dans les données d'entrée, ce qui permet d'enrichir la représentation des caractéristiques et d'améliorer la capacité du modèle à effectuer des prédictions précises.

La 3eme couche LSTM sans return_sequences se concentre sur les dépendances à court terme, en fin de séquence. Elle mémorise les infos récentes déterminants pour la prévision.


Enfin, les couches densées combinent les représentations multi-échelles temporelles pour réaliser la régression précise vers la valeur cible.


En conclusion, cette archi LSTM à memoire permet de modéliser finement les différents  horizons temporels présents dans la série, du global au local. Le nombre de neurones. La taille des filtres et la régularisation ont été optimisés pour minimiser l'erreur MSE sur la validation, sans sur-apprentissage . Le modèle résultant prédit avec précision les fluctuations futures  .
